{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "In this notebook, we will show you how we profile and optimize a canonical computer vision training instance: *ResNet50 + CIFAR100*. In the end, we would achive near 10x speedup from the baseline.\n",
    "\n",
    "The notebook is brokendown into \"Optimization stages\", were we incrementally permute our training pipeline to perform system-level optimization on different parts\n",
    "of the training logic. \n",
    "\n",
    "Please follow along this notebook, follow the comments that show ########## Optimization X ################### for code changes in each optimization stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kcB0zwMCdLA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXYuWN4_gRh4"
   },
   "source": [
    "## Model\n",
    "We include a basic implementation of ResNet50 based on torchvision's implementation, but removes \n",
    "the extra boilerplate code for better readability.\n",
    "Please navigate to `model.py` to check model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGfkrKemCl50"
   },
   "outputs": [],
   "source": [
    "from model import ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mef7QUjNgkcf"
   },
   "source": [
    "## Data\n",
    "For the notebook to run in a reasonable time, we pick CIFAR100 as our dataloader, which is an image dataset with 3x32x32 images from 100 classes.\n",
    "\n",
    "We select a few data-augmentation techniques, they include:\n",
    "* Crop\n",
    "* Horizontal Flip\n",
    "* Gaussian blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jSe003_Sglv3"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def get_loaders(train_bs, val_bs):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False)\n",
    "  \n",
    "  return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SV_reOX8gU9X"
   },
   "source": [
    "## Training\n",
    "This training loop below is a standard supervised image classification training procedure as suggested by PyTorch examples.\n",
    "Please skim over this quickly as the details (such as logging, and metrics reporting) don't matter as much for our workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nB0takEVh9E2"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.notebook import  tqdm\n",
    "import sys, os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcDAxY3AjX1Y"
   },
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "end_epoch = 2\n",
    "lr = 0.1\n",
    "best_acc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USprdxU8jhOI"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VnQ4n4zEJ2M"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, epoch, trainloader, prof=None):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(total=len(trainloader), file=sys.stdout, ncols=800) as pbar:\n",
    "      for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "          inputs, targets = inputs.to(device), targets.to(device)\n",
    "          optimizer.zero_grad()\n",
    "          outputs = model(inputs)\n",
    "          loss = criterion(outputs, targets)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          train_loss += loss.item()\n",
    "          _, predicted = outputs.max(-1)\n",
    "          total += targets.size(0)\n",
    "          correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "          pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                      % (batch_idx, len(trainloader), train_loss/(batch_idx+1), \n",
    "                          100.*correct/total, correct, total),)\n",
    "          pbar.update(1)\n",
    "          \n",
    "          if prof is not None:\n",
    "            prof.step()\n",
    "            if batch_idx == 20:\n",
    "              return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, optimizer, epoch, testloader):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "      with tqdm(total=len(testloader), file=sys.stdout, ncols=800) as pbar:\n",
    "\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(-1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (batch_idx, len(testloader), test_loss/(batch_idx+1), \n",
    "                            100.*correct/total, correct, total),)\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "The baseline simply runs the training loop for 2 epochs, and reports the training time for the second epoch (when things are more stable).\n",
    "\n",
    "We use `tqdm` to report training progression for each epoch, As it trains, you should notice the loss on the left of the progress bar to decrease, as well as the iteration time on the right of the progress bar.\n",
    "\n",
    "The expected runtime for this snippet is 160 (80*2) seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "LxanaJZzEndq",
    "outputId": "015b9a5d-98fc-4379-83b0-bfe6f6fc73c4"
   },
   "outputs": [],
   "source": [
    "trainloader, valloader = get_loaders(128, 128)\n",
    "import torchvision\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    \n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "\n",
    "baseline_time = epoch_end_time - epoch_start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling with torch.profiler\n",
    "\n",
    "We choose to profile with the built-in PyTorch profiler for its ease of use. \n",
    "\n",
    "For more detailed profiling, you could also use `vtune` (for Intel CPU), `nsys` (for NVIDIA GPU), and\n",
    "other vendor-specific profiling tools. \n",
    "\n",
    "However, they require more careful installation and\n",
    "launching procedures, which we do not have the resources to cover here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader = get_loaders(128, 128)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "\n",
    "with torch.profiler.profile(\n",
    "        activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "        schedule=torch.profiler.schedule(skip_first=10, wait=5, warmup=1, active=1, repeat=1),\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./profile/baseline'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True\n",
    ") as prof:\n",
    "    train(model, optimizer, 0, trainloader, prof)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open profiled results\n",
    "\n",
    "* Open Command Pallet (Top-left Button -> View -> Command Pallet) or Press `Control (or Command for MacOS) + Shift + P` for Chrome\n",
    "* Search for `Launch Tensorboard`\n",
    "* Select `Launch Tensorboard` and select `Select another folder` from the drop-down medu\n",
    "* Select ./project/profile as the log dir from the drop down mene\n",
    "* Press OK\n",
    "* When prompted Tensorboard, select `Open in Browser` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization1: re-order augmentation \n",
    "The first optimization concerns with data-augmentation.\n",
    "While many augmentation techniques are insensitive to ordering (i.e. crop after blur is identical to blur after crop),\n",
    "the performance implications are significant.\n",
    "\n",
    "Instead of issuing `ToTensor` last, we issue `ToTensor` first in the data augmentation pipeline, this would allow\n",
    "subsequent operations to run with `Tensor` objects which have better hardware utilization due to its better implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "    ####### OPTIMIZATION 1 #################\n",
    "      transforms.ToTensor(),\n",
    "    ####### OPTIMIZATION 1 #################\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False)\n",
    "  \n",
    "  return trainloader, testloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s2KGJdWLpNpa"
   },
   "outputs": [],
   "source": [
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "trainloader, valloader = get_loaders(128, 128)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 2: pin_memory, pre-fetching, and batch_size\n",
    "By default, PyTorch does not enable data pre-fetching or loading data with multiple CPUs.\n",
    "\n",
    "To enable this, we need to set the `num_workers` argument in the dataloader.\n",
    "For a single GPU training setup, the best number is `number of cpus - 1 on your machine (7 in this case)`.\n",
    "\n",
    "Similarly, for GPU tensors, `pin_memory=True` would allow CPU tensors to be directly created in the pinned memory region,\n",
    "which is then copied to the GPU. Otherwise, we would incur an extra CPU-CPU copy.\n",
    "\n",
    "Lastly, batch size should be increased to the maximum of what your algorithm allows (for convergence) and what your hardware\n",
    "allows (before getting out of memory) for the best GPU utilization due to increased parallelism and memory reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "    ####### OPTIMIZATION 2.1 #################\n",
    "      trainset, batch_size=train_bs, shuffle=True,\n",
    "      pin_memory=True,\n",
    "      num_workers=7,\n",
    "    ####### OPTIMIZATION 2.1 #################\n",
    "  )\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "    ####### OPTIMIZATION 2 #################\n",
    "      testset, batch_size=val_bs, shuffle=False,\n",
    "      pin_memory=True,\n",
    "      num_workers=7,\n",
    "    ####### OPTIMIZATION 2 #################\n",
    "  )\n",
    "  \n",
    "  return trainloader, testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DS6-O6yj0QVY"
   },
   "outputs": [],
   "source": [
    "####### OPTIMIZATION 2.2 #################\n",
    "trainloader, valloader = get_loaders(256, 512)\n",
    "####### OPTIMIZATION 2.2 #################\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 3: Mixed precision training\n",
    "GPUs after Volta microarchitecture (V100, T4, A100, H100, etc) features TensorCores. \n",
    "\n",
    "These are much faster compute units than traditional 32-bit IEEE-754 floating numbers. Mixed precision leverages \n",
    "these tensor-cores and does additional numerical adjustments to recover the numerical discrepancies (although not identical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, grad_scalar, epoch, trainloader, prof=None):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(total=len(trainloader), file=sys.stdout, ncols=800) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "    ####### OPTIMIZATION 3.1 #################\n",
    "            with torch.autocast(device_type=device):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "    ####### OPTIMIZATION 3.1 #################\n",
    "            \n",
    "    ####### OPTIMIZATION 3.2 #################\n",
    "            grad_scalar.scale(loss).backward()\n",
    "            grad_scalar.step(optimizer)\n",
    "            grad_scalar.update()\n",
    "    ####### OPTIMIZATION 3.2 #################\n",
    "        \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(-1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                        % (batch_idx, len(trainloader), train_loss/(batch_idx+1), \n",
    "                            100.*correct/total, correct, total),)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if prof is not None:\n",
    "                prof.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xo6VNWKC0hi3"
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.benchmark = True\n",
    "torch.backends.cuda.deterministic = False\n",
    "\n",
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "\n",
    "####### OPTIMIZATION 3.3 #################\n",
    "model.to(memory_format=torch.channels_last)\n",
    "####### OPTIMIZATION 3.3 #################\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 4: Fused optimizer\n",
    "Optimizer updates involve many element-wise operations (add, exp, mul, etc).\n",
    "\n",
    "These operations result in frequent but short-lived GPU kernels, which are very inefficient. \n",
    "\n",
    "As a result, NVIDIA provides fused optimizers (for a few common choices) which make the optimizer updates go faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrYNH64m4hv-"
   },
   "outputs": [],
   "source": [
    "import apex\n",
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "model.to(memory_format=torch.channels_last)\n",
    "\n",
    "####### OPTIMIZATION 4 #################\n",
    "optimizer = apex.optimizers.FusedAdam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "####### OPTIMIZATION 4 #################\n",
    "\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 5: torch.jit\n",
    "Just-in-time compilation is a technique to compile PyTorch models for better utilization.\n",
    "\n",
    "The details of jit require another session to explain, but the APIs are pretty simple, please see below. \n",
    "\n",
    "Jit works best with static input shapes, so we make the dataloader to `drop_last`, which keeps the batch size \n",
    "always consistent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(train_bs, val_bs,):\n",
    "\n",
    "  transform_train = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.RandomCrop(32, padding=4),\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.GaussianBlur(3),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  transform_test = transforms.Compose([\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "  ])\n",
    "\n",
    "  trainset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=True, download=True, transform=transform_train)\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "      trainset, batch_size=train_bs, shuffle=True,\n",
    "      pin_memory=True,\n",
    "      num_workers=8,\n",
    "    ####### OPTIMIZATION 5.1 #################\n",
    "      drop_last=True,\n",
    "    ####### OPTIMIZATION 5.1 #################\n",
    "  )\n",
    "\n",
    "  testset = torchvision.datasets.CIFAR100(\n",
    "      root='./data', train=False, download=True, transform=transform_test)\n",
    "  testloader = torch.utils.data.DataLoader(\n",
    "      testset, batch_size=val_bs, shuffle=False,\n",
    "      pin_memory=True,\n",
    "      num_workers=8,\n",
    "    ####### OPTIMIZATION 5.2 #################\n",
    "      drop_last=True,\n",
    "    ####### OPTIMIZATION 5.2 #################\n",
    "  )\n",
    "  \n",
    "  return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "model.to(memory_format=torch.channels_last)\n",
    "\n",
    "####### OPTIMIZATION 5.3 #################\n",
    "traced_model = torch.jit.trace(model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "####### OPTIMIZATION 5.3 #################\n",
    "\n",
    "optimizer = apex.optimizers.FusedAdam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(traced_model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 6: CUDAGraph\n",
    "\n",
    "CUDAGraph captures the sequence of GPU operations and optimizes them into a single GPU operation. This reduces overhead significantly.\n",
    "\n",
    "CUDAGraph also requires static shapes and computation patterns, which have limited use-cases. Please use it with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "model.to(memory_format=torch.channels_last)\n",
    "\n",
    "traced_model = torch.jit.trace(model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "\n",
    "####### OPTIMIZATION 6 #################\n",
    "with torch.amp.autocast(device_type=device):\n",
    "    graphed_model = torch.cuda.make_graphed_callables(traced_model, (torch.rand(256, 3, 32, 32, device=device),))\n",
    "####### OPTIMIZATION 6 #################\n",
    "\n",
    "optimizer = apex.optimizers.FusedAdam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train(graphed_model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    test(model, optimizer, epoch, valloader)\n",
    "    scheduler.step()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time / (epoch_end_time - epoch_start_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "Optimizations are heavily dependent on your workload and metrics, and is fairly complex. The code changes above may look simple, but it was a significant engineering effort to interatively profile and subsequently modify the source code. One would argue that: a performance engineer can only be as good as the profiler she uses :)\n",
    "\n",
    "With that, I'd like to introduce a new open-source in-editor profiler, Sklyline, presented by my coleague Yubo Gao."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization 7: (Optional) Horizontal Fusion\n",
    "In many use-cases, we often need to train models many times with different hyper-parameters \n",
    "to find the best model for our dataset (i.e. learning rates, etc).\n",
    "\n",
    "Usually this is done by appending an outer-loop to the training script, which takes longer, or\n",
    "one would use multiple GPUs, which takes more hardware resources and money. \n",
    "\n",
    "CentML has a mechanism to let you train multiple models on a single GPU, but with almost the same\n",
    "amount of time as training a single model. We call this `Horizontal Fusion`. \n",
    "\n",
    "Our open-sourced version (for academic research) is at (https://uoft-ecosystem.github.io/hfta/). \n",
    "In this tutorial, we will use a more polished version developed by CentML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install git+https://github.com/CentML/hfta\n",
    "from hfta.optim import Adam as ParallelAdam\n",
    "from auto_hfta.make_parallel import make_parallel\n",
    "from auto_hfta.utils import ClsLossWrapper\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "num_models = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_parallel(model, optimizer, grad_scalar, epoch, trainloader, prof=None):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with tqdm(total=len(trainloader), file=sys.stdout, ncols=800) as pbar:\n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputs = inputs.unsqueeze(0).expand(num_models, *([-1] * inputs.dim()))\n",
    "            targets = targets.unsqueeze(0).expand(num_models, *([-1] * targets.dim()))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.autocast(device_type=device):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "            \n",
    "            grad_scalar.scale(loss).backward()\n",
    "            grad_scalar.step(optimizer)\n",
    "            grad_scalar.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(-1)\n",
    "            total += targets.size(1)\n",
    "            correct += predicted.eq(targets).sum(-1)\n",
    "\n",
    "            pbar.set_description('[%3d]/[%3d]Loss: %.3f | Acc: %.3f%%, %.3f%% (%d, %d/%d)'\n",
    "                        % (batch_idx, len(trainloader), train_loss/(batch_idx+1), \n",
    "                            *(100.* correct/total), *correct, total),)\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if prof is not None:\n",
    "                prof.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "trainloader, valloader = get_loaders(256, 512)\n",
    "\n",
    "model = ResNet50(num_classes=100).to(device)\n",
    "model.train()\n",
    "\n",
    "####### OPTIMIZATION 7 #################\n",
    "model = make_parallel(model, num_parallel=num_models, out_device='cuda',)\n",
    "####### OPTIMIZATION 7 #################\n",
    "\n",
    "optimizer = apex.optimizers.FusedAdam(model.parameters(), lr=lr,weight_decay=5e-4)\n",
    "\n",
    "# if you want to have different learning rates\n",
    "# optimizer = ParallelAdam(model.parameters(), lr=[lr, lr * 2], weight_decay=5e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = ClsLossWrapper(criterion)\n",
    "\n",
    "grad_scalar = torch.cuda.amp.GradScaler()\n",
    "\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    train_parallel(model, optimizer, grad_scalar, epoch, trainloader)\n",
    "    epoch_end_time = time.time()\n",
    "    if epoch > 0:\n",
    "        print(\"Training for one epoch takes {:.3f}s\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"Speedup over baseline: {:.2f}\".format(baseline_time * num_models / (epoch_end_time - epoch_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect with us\n",
    "Please email xin@centml.ai for any questions !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
